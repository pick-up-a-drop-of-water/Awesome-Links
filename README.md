##  ğŸ”— Blog Links =>ã€mineã€‘
> - [win10ä¸‹å®ç°å®šæ—¶æ‰§è¡Œpythonç¨‹åºçš„batè„šæœ¬](https://blog.csdn.net/weixin_43982238/article/details/93001262)
> - [Ubuntuåˆ©ç”¨crontabå‘½ä»¤å¼€å¯å®šæ—¶ä»»åŠ¡å¹¶åŠ å…¥å¼€æœºè‡ªå¯åŠ¨æœåŠ¡](https://blog.csdn.net/weixin_43982238/article/details/91988952)
> - [åˆè¯† â¤ TensorFlow |ã€ä¸€è§å€¾å¿ƒã€‘](https://blog.csdn.net/weixin_43982238/article/details/92686173)
> - [åˆè§ â¤ RNN |ã€å­¦ä»¥è‡´ç”¨ã€‘](https://blog.csdn.net/weixin_43982238/article/details/94646802)
> - [åä¸º2019æ ¡æ‹›ç¬”è¯•é¢˜ä¹‹å¤„ç†å­—ç¬¦ä¸²(pythonç‰ˆ)](https://blog.csdn.net/weixin_43982238/article/details/91350464)
> - [åä¸º2019æ ¡æ‹›ç¬”è¯•é¢˜ä¹‹æ—‹è½¬æ–¹é˜µ(pythonç‰ˆ)](https://blog.csdn.net/weixin_43982238/article/details/92812419)
> - [ã€æ›´æ–°ingã€‘Awesome Links](https://blog.csdn.net/weixin_43982238/article/details/95607765)
> - [ã€ä»£ç DIYã€‘ä¹‹ã€ç»˜åˆ¶ROCã€P-Ræ›²çº¿ã€‘](https://blog.csdn.net/weixin_43982238/article/details/97157696)ğŸ¨
##  âŒ› Python Links
> - [Python æ•™ç¨‹é˜…è¯»ç®€è®°](https://chyroc.cn/posts/python-tutorial-notes/)
> - [Python ç›¸å…³é¢è¯•é¢˜](https://github.com/taizilongxu/interview_python)
##  ğŸ”µ Deep Learning
> - [Deep Learning | NLP | Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)
> - [å®Œå…¨å›¾è§£RNNã€RNNå˜ä½“ã€Seq2Seqã€Attentionæœºåˆ¶](https://www.leiphone.com/news/201709/8tDpwklrKubaecTa.html)
> - [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
> - [Attentionæœºåˆ¶](https://luozhouyang.github.io/attetnion_mechanism/)
> - [How to Visualize Your Recurrent Neural Network with Attention in Keras](https://medium.com/datalogue/attention-in-keras-1892773a4f22)
> - [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)
> - [Attention in GIFs and how it is used in machine translation like Google Translate](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)
> - [How To Improve Deep Learning Performance](https://machinelearningmastery.com/improve-deep-learning-performance/)
##  ğŸ’­ Academic Frontier
> - [Google AI ã€VPNã€‘](https://ai.googleblog.com/)
##  ğŸ’¦ Code links
> - [Neural Machine Translation with Attention
](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb
)
> - [Multi-task Learning in Keras](https://blog.manash.me/multi-task-learning-in-keras-implementation-of-multi-task-classification-loss-f1d42da5c3f6?gi=a1121f1f752d)
> - [Attention-based Sequence-to-Sequence in Keras](https://wanasit.github.io/attention-based-sequence-to-sequence-in-keras.html)
> - [Structuring Your TensorFlow Models](https://danijar.com/structuring-your-tensorflow-models/)
##  ğŸ” Tutorial links
> - [å‡ ä¹æ‰€æœ‰ä¸æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ç›¸å…³çš„æ•™ç¨‹(with code)](https://machinelearningmastery.com/start-here/) ğŸ‘
