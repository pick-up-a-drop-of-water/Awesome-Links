##  🔗 Blog Links =>【mine】
> - [win10下实现定时执行python程序的bat脚本](https://blog.csdn.net/weixin_43982238/article/details/93001262)
> - [Ubuntu利用crontab命令开启定时任务并加入开机自启动服务](https://blog.csdn.net/weixin_43982238/article/details/91988952)
> - [初识 ❤ TensorFlow |【一见倾心】](https://blog.csdn.net/weixin_43982238/article/details/92686173)
> - [初见 ❤ RNN |【学以致用】](https://blog.csdn.net/weixin_43982238/article/details/94646802)
> - [华为2019校招笔试题之处理字符串(python版)](https://blog.csdn.net/weixin_43982238/article/details/91350464)
> - [华为2019校招笔试题之旋转方阵(python版)](https://blog.csdn.net/weixin_43982238/article/details/92812419)
> - [【更新ing】Awesome Links](https://blog.csdn.net/weixin_43982238/article/details/95607765)
> - [【代码DIY】之【绘制ROC、P-R曲线】](https://blog.csdn.net/weixin_43982238/article/details/97157696)🎨
##  ⌛ Python Links
> - [Python 教程阅读简记](https://chyroc.cn/posts/python-tutorial-notes/)
> - [Python 相关面试题](https://github.com/taizilongxu/interview_python)
##  🔵 Deep Learning
> - [Deep Learning | NLP | Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)
> - [完全图解RNN、RNN变体、Seq2Seq、Attention机制](https://www.leiphone.com/news/201709/8tDpwklrKubaecTa.html)
> - [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
> - [Attention机制](https://luozhouyang.github.io/attetnion_mechanism/)
> - [How to Visualize Your Recurrent Neural Network with Attention in Keras](https://medium.com/datalogue/attention-in-keras-1892773a4f22)
> - [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)
> - [Attention in GIFs and how it is used in machine translation like Google Translate](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)
> - [How To Improve Deep Learning Performance](https://machinelearningmastery.com/improve-deep-learning-performance/)
##  💭 Academic Frontier
> - [Google AI 【VPN】](https://ai.googleblog.com/)
##  💦 Code links
> - [Neural Machine Translation with Attention
](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb
)
> - [Multi-task Learning in Keras](https://blog.manash.me/multi-task-learning-in-keras-implementation-of-multi-task-classification-loss-f1d42da5c3f6?gi=a1121f1f752d)
> - [Attention-based Sequence-to-Sequence in Keras](https://wanasit.github.io/attention-based-sequence-to-sequence-in-keras.html)
> - [Structuring Your TensorFlow Models](https://danijar.com/structuring-your-tensorflow-models/)
##  🔎 Tutorial links
> - [几乎所有与机器学习、深度学习相关的教程(with code)](https://machinelearningmastery.com/start-here/) 👍
